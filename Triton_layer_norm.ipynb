{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNo4xoIPfeHAfRYzUtBnUaA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soulsharp/Triton_kernels_ViT/blob/main/Triton_layer_norm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install triton"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyQXRo1JnCnZ",
        "outputId": "bd79d79f-0aa0-4521-b308-e6fae92ff6b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting triton\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton) (3.16.1)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton\n",
            "Successfully installed triton-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsqazg8Omml5"
      },
      "outputs": [],
      "source": [
        "import triton\n",
        "import triton.language as tl\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.jit\n",
        "def _layer_norm_forward(\n",
        "    input_ptr, # Pointer to input, 2D\n",
        "    output_ptr, # Pointer to output, 2D\n",
        "    weight_ptr, # Pointer to weights, shape : (num_cols, 1)\n",
        "    bias_ptr, # Pointer to biases, shape : (num_cols, 1)\n",
        "    mean_vector_ptr, # Row-wise mean, shape:(num_rows, 1)\n",
        "    rstd_ptr, # Row-wise reciprocal of standard deviation, shape:(num_rows, 1)\n",
        "    xhat_ptr, # Stores xhat values for backward pass\n",
        "    row_stride,\n",
        "    num_cols,\n",
        "    epsilon, # For numerical stability\n",
        "    BLOCK_SIZE:tl.constexpr,\n",
        "  ):\n",
        "\n",
        "  pid = tl.program_id(0)\n",
        "  input_ptr += pid * row_stride\n",
        "  output_ptr += pid * row_stride\n",
        "\n",
        "  # Initializes mean accumulator and squared sum accumulator with zeros\n",
        "  mean_acc = tl.zeros([BLOCK_SIZE], dtype=tl.float32)\n",
        "  squared_sum_acc = tl.zeros([BLOCK_SIZE], dtype=tl.float32)\n",
        "\n",
        "  # Processes a row in chunks\n",
        "  for offset in range(0, num_cols, BLOCK_SIZE):\n",
        "      offsets = offset + tl.arange(0, BLOCK_SIZE)\n",
        "      mask = offsets < num_cols\n",
        "\n",
        "      # Loads a segment of the row\n",
        "      row_segment = tl.load(input_ptr + offsets, mask=mask, other=0.).to(tl.float32)\n",
        "\n",
        "      # Accumulates sums and squared sums\n",
        "      mean_acc += row_segment\n",
        "      squared_sum_acc += row_segment * row_segment\n",
        "\n",
        "  # Aggregates partial sums and partial squared sums\n",
        "  mean = tl.sum(mean_acc, axis=0) / num_cols\n",
        "  mean_squared_sum = tl.sum(squared_sum_acc, axis=0) / num_cols\n",
        "\n",
        "  # Variance and rstd\n",
        "  variance = mean_squared_sum - mean * mean\n",
        "  rstd = 1.0 / tl.sqrt(variance + epsilon)\n",
        "\n",
        "  # Stores mean and rstd\n",
        "  tl.store(mean_vector_ptr + pid, mean)\n",
        "  tl.store(rstd_ptr + pid, rstd)\n",
        "\n",
        "  # Normalizes inputs and stores y as output\n",
        "  for offset in range(0, num_cols, BLOCK_SIZE):\n",
        "      offsets = offset + tl.arange(0, BLOCK_SIZE)\n",
        "      mask = offsets < num_cols\n",
        "\n",
        "      # Loads a segment of the row, corresponding weights and biases\n",
        "      row_segment = tl.load(input_ptr + offsets, mask=mask, other=0.).to(tl.float32)\n",
        "      weights = tl.load(weight_ptr + offsets, mask=mask)\n",
        "      biases = tl.load(bias_ptr + offsets, mask=mask)\n",
        "\n",
        "      # Computes normalized inputs\n",
        "      delta = row_segment - mean\n",
        "      xhat = delta * rstd\n",
        "      y = weights * xhat + biases\n",
        "\n",
        "      # Writes output\n",
        "      tl.store(output_ptr + offsets, y, mask=mask)\n",
        "      tl.store(xhat_ptr + offsets, xhat, mask=mask)\n"
      ],
      "metadata": {
        "id": "bbJmLpAB9ebY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.jit\n",
        "def _backward_pass_layer_norm(\n",
        "    Dy, # Gradient of loss wrt y\n",
        "    Dx, # Gradient of loss wrt x(inputs, to be calculated)\n",
        "    Dw, # Gradient of loss wrt weights(to be calculated)\n",
        "    Db, # Gradient of loss wrt biases(to be calculated)\n",
        "    input_ptr,\n",
        "    weights_ptr\n",
        "    mean_vector_ptr,\n",
        "    wdy_ptr, # intermediate ptr to store the values of w@dy\n",
        "    rstd_ptr,\n",
        "    xhat_ptr,\n",
        "    row_stride,\n",
        "    num_cols,\n",
        "    GROUP_SIZE_M: tl.constexpr,\n",
        "    BLOCK_SIZE: tl.constexpr\n",
        " ):\n",
        "\n",
        " pid = tl.program_id(0)\n",
        " row_idx = pid * row_stride\n",
        " num_blocks = tl.cdiv(num_cols, BLOCK_SIZE)\n",
        "\n",
        " # Shared mem arrays to compute dot products after accumulation of partial sums\n",
        " dot_sum_xwdy = tl.zeros([num_blocks])\n",
        " dot_sum_wdy = tl.zeros([num_blocks])\n",
        "\n",
        " # Gets the row_wise mean and standard deviation depending upon program id\n",
        " mean_value = tl.load(mean_vector_ptr + pid)\n",
        " rstd_value = tl.load(rstd_ptr + pid)\n",
        "\n",
        " for block_id in range(num_blocks):\n",
        "    start_idx = block_id * BLOCK_SIZE\n",
        "    offsets = start_idx + tl.arange(0, BLOCK_SIZE)\n",
        "    mask = offsets < num_cols\n",
        "\n",
        "    # Loads a bunch of different blocks of values for computation\n",
        "    grad_y = tl.load(Dy + row_idx + offsets, mask=mask)\n",
        "    weight_values = tl.load(weights_ptr + row_idx + offsets, mask=mask)\n",
        "    xhat = tl.load(xhat_ptr + row_idx + offsets, mask=mask)\n",
        "\n",
        "    # Computes vectors required for the calculation of Dx\n",
        "    wdy = grad_y * weight_values\n",
        "\n",
        "    # Accumulates partial sums of dot products in shared memory\n",
        "    dot_sum_xwdy[block_id] = tl.sum(xhat * wdy, axis = 0)\n",
        "    dot_sum_wdy[block_id] = tl.sum(grad_y * weight_values, axis=0)\n",
        "\n",
        " # Constants required for calculation of Dx\n",
        " c1 = tl.sum(dot_sum_xwdy, axis=0) / num_cols\n",
        " c2 = tl.sum(dot_sum_wdy, axis=0) / num_cols\n",
        "\n",
        " for block_id in range(num_blocks):\n",
        "    start_idx = block_id * BLOCK_SIZE\n",
        "    offsets = start_idx + tl.arange(0, BLOCK_SIZE)\n",
        "    mask = offsets < num_cols\n",
        "\n",
        "    # Loads a bunch of different blocks of values for computation\n",
        "    grad_y = tl.load(Dy + row_idx + offsets, mask=mask)\n",
        "    weight_values = tl.load(weights_ptr + row_idx + offsets, mask=mask)\n",
        "    xhat = tl.load(xhat_ptr + row_idx + offsets, mask=mask)\n",
        "\n",
        "    # xhat = delta / rstd_value\n",
        "    wdy = grad_y * weight_values\n",
        "\n",
        "    # Core computation\n",
        "    grad_x = (wdy - c1 * xhat - c2) * rstd_value\n",
        "\n",
        "    tl.store(Dx + offsets ,grad_x, mask=mask)\n"
      ],
      "metadata": {
        "id": "YcmHicoGS2Rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "NUM_ROWS = 4  # Number of rows in the input matrix\n",
        "NUM_COLS = 16  # Number of columns in the input matrix\n",
        "BLOCK_SIZE = 8  # Block size for Triton kernel\n",
        "EPSILON = 1e-5  # Small constant for numerical stability\n",
        "\n",
        "# Input data\n",
        "input_tensor = torch.randn((NUM_ROWS, NUM_COLS), dtype=torch.float32, device='cuda')\n",
        "output_tensor = torch.zeros_like(input_tensor, device='cuda')\n",
        "weight_tensor = torch.ones(NUM_COLS, dtype=torch.float32, device='cuda')\n",
        "bias_tensor = torch.zeros(NUM_COLS, dtype=torch.float32, device='cuda')\n",
        "mean_vector = torch.zeros(NUM_ROWS, dtype=torch.float32, device='cuda')\n",
        "rstd_vector = torch.zeros(NUM_ROWS, dtype=torch.float32, device='cuda')\n",
        "\n",
        "# Strides\n",
        "row_stride = input_tensor.stride(0)\n",
        "\n",
        "# Launch kernel\n",
        "layer_norm_forward[(NUM_ROWS,)](\n",
        "    input_tensor,\n",
        "    output_tensor,\n",
        "    weight_tensor,\n",
        "    bias_tensor,\n",
        "    mean_vector,\n",
        "    rstd_vector,\n",
        "    row_stride,\n",
        "    NUM_COLS,\n",
        "    EPSILON,\n",
        "    BLOCK_SIZE=BLOCK_SIZE\n",
        ")\n",
        "\n",
        "_layer_norm_fwd_test[(NUM_ROWS,)](\n",
        "    input_tensor,\n",
        "    output_tensor,\n",
        "    weight_tensor,\n",
        "    bias_tensor,\n",
        "    mean_vector,\n",
        "    rstd_vector,\n",
        "    row_stride,\n",
        "    NUM_COLS,\n",
        "    EPSILON,\n",
        "    BLOCK_SIZE=BLOCK_SIZE\n",
        ")\n",
        "\n",
        "# Retrieve and verify results\n",
        "print(\"Input Tensor:\")\n",
        "print(input_tensor.cpu().numpy())\n",
        "print(\"Mean Vector:\")\n",
        "print(mean_vector.cpu().numpy())\n",
        "print(\"Rstd Vector:\")\n",
        "print(rstd_vector.cpu().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTopYP9OoP9X",
        "outputId": "df02d820-d5d9-4c14-d523-41b46fbb300e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Tensor:\n",
            "[[ 0.17184934  0.47160515  0.33827543  0.27657324 -0.7147892   0.51168585\n",
            "  -0.19860959 -0.11520658  1.1411026  -0.77810264 -0.78735423 -0.55497736\n",
            "  -0.3488355  -0.4574265  -0.59218186 -1.3202435 ]\n",
            " [-0.07285843 -0.50958127 -0.8654773   0.726394    0.37132856 -0.88880646\n",
            "   1.460418    1.1474667   0.2841265  -0.81712204  0.81673616 -0.1994375\n",
            "   0.92693114 -0.2802274   0.58567303 -0.03764753]\n",
            " [-1.0386246  -0.2645126  -0.00845453  1.0592384   1.7422706  -1.1534754\n",
            "   0.8803959   1.2779768  -0.7138989  -1.7249111  -1.1983298  -0.731013\n",
            "  -0.28897485 -0.16875947 -0.55907196  0.5937596 ]\n",
            " [-0.5679358  -0.2420803   0.46496576  0.32869694 -0.3844268   0.2112381\n",
            "  -0.5294461   0.7774498  -0.49508306  1.892584   -0.0091246   1.0345228\n",
            "   0.47390002  0.56024647 -0.87162644 -0.9639047 ]]\n",
            "Mean Vector:\n",
            "[-0.18478972  0.16549478 -0.14352408  0.1049985 ]\n",
            "Rstd Vector:\n",
            "[1.6354115 1.3952965 1.0345864 1.3537248]\n"
          ]
        }
      ]
    }
  ]
}